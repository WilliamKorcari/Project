{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# pandas\n",
    "from pandas import read_csv\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#teras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC, Accuracy, Precision, Recall, FalsePositives\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Which is the name of the dataset? analysis.csv\n",
      "\n",
      "Select first column: \n",
      "2\n",
      "\n",
      "Select last col: \n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = input('\\nWhich is the name of the dataset? ')\n",
    "dataframe = read_csv(dataset, header=0)\n",
    "dataset = dataframe.values\n",
    "#dataset = np.random.shuffle(dataset)\n",
    "first_col = input(\"\\nSelect first column: \\n\") #2\n",
    "last_col = input('\\nSelect last col: \\n')          #15\n",
    "\n",
    "X = dataset[:,int(first_col):int(last_col)].astype(float)   # columns from 3rd to 14th into X\n",
    "Y = dataset[:,int(last_col)] #label column (15th) into Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "#One-hot encoding\n",
    "transformed_Y = to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialising NN\n",
    "model = Sequential()\n",
    "\n",
    "#First layer\n",
    "model.add(Dense(8, activation='relu', input_shape=(13,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Second layer\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr= 0.0001),\n",
    "              metrics=[Precision(name = 'precision'),\n",
    "                       Recall(name = 'recall')]\n",
    "             )\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "                                                    transformed_Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=seed,\n",
    "                                                    shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3040026 samples, validate on 760007 samples\n",
      "Epoch 1/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.9211 - precision: 0.3842 - recall: 0.2218 - val_loss: 0.8262 - val_precision: 0.5640 - val_recall: 0.8896\n",
      "Epoch 2/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.9089 - precision: 0.3845 - recall: 0.2222 - val_loss: 0.7753 - val_precision: 0.5761 - val_recall: 0.6458\n",
      "Epoch 3/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8978 - precision: 0.3857 - recall: 0.2230 - val_loss: 0.7617 - val_precision: 0.6367 - val_recall: 0.4363\n",
      "Epoch 4/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8865 - precision: 0.3870 - recall: 0.2241 - val_loss: 0.7575 - val_precision: 0.6046 - val_recall: 0.3078\n",
      "Epoch 5/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8756 - precision: 0.3893 - recall: 0.2253 - val_loss: 0.7566 - val_precision: 0.5807 - val_recall: 0.2489\n",
      "Epoch 6/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8653 - precision: 0.3914 - recall: 0.2266 - val_loss: 0.7567 - val_precision: 0.5717 - val_recall: 0.2215\n",
      "Epoch 7/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8553 - precision: 0.3945 - recall: 0.2284 - val_loss: 0.7570 - val_precision: 0.5711 - val_recall: 0.2072\n",
      "Epoch 8/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8461 - precision: 0.3979 - recall: 0.2306 - val_loss: 0.7571 - val_precision: 0.5728 - val_recall: 0.1982\n",
      "Epoch 9/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8371 - precision: 0.4020 - recall: 0.2325 - val_loss: 0.7566 - val_precision: 0.5758 - val_recall: 0.1923\n",
      "Epoch 10/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8280 - precision: 0.4065 - recall: 0.2354 - val_loss: 0.7555 - val_precision: 0.5772 - val_recall: 0.1878\n",
      "Epoch 11/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8191 - precision: 0.4112 - recall: 0.2379 - val_loss: 0.7539 - val_precision: 0.5713 - val_recall: 0.1843\n",
      "Epoch 12/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8109 - precision: 0.4171 - recall: 0.2413 - val_loss: 0.7516 - val_precision: 0.5556 - val_recall: 0.1815\n",
      "Epoch 13/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.8033 - precision: 0.4227 - recall: 0.2451 - val_loss: 0.7488 - val_precision: 0.5358 - val_recall: 0.1791\n",
      "Epoch 14/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7958 - precision: 0.4289 - recall: 0.2484 - val_loss: 0.7457 - val_precision: 0.5175 - val_recall: 0.1769\n",
      "Epoch 15/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7880 - precision: 0.4365 - recall: 0.2534 - val_loss: 0.7419 - val_precision: 0.5032 - val_recall: 0.1748\n",
      "Epoch 16/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7807 - precision: 0.4436 - recall: 0.2578 - val_loss: 0.7377 - val_precision: 0.4936 - val_recall: 0.1728\n",
      "Epoch 17/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7737 - precision: 0.4510 - recall: 0.2627 - val_loss: 0.7332 - val_precision: 0.4880 - val_recall: 0.1706\n",
      "Epoch 18/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7670 - precision: 0.4590 - recall: 0.2682 - val_loss: 0.7283 - val_precision: 0.4871 - val_recall: 0.1685\n",
      "Epoch 19/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7602 - precision: 0.4686 - recall: 0.2748 - val_loss: 0.7233 - val_precision: 0.4895 - val_recall: 0.1666\n",
      "Epoch 20/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7542 - precision: 0.4773 - recall: 0.2807 - val_loss: 0.7180 - val_precision: 0.4957 - val_recall: 0.1653\n",
      "Epoch 21/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7478 - precision: 0.4866 - recall: 0.2875 - val_loss: 0.7125 - val_precision: 0.5065 - val_recall: 0.1647\n",
      "Epoch 22/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7418 - precision: 0.4962 - recall: 0.2947 - val_loss: 0.7070 - val_precision: 0.5219 - val_recall: 0.1653\n",
      "Epoch 23/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7358 - precision: 0.5070 - recall: 0.3032 - val_loss: 0.7013 - val_precision: 0.5424 - val_recall: 0.1674\n",
      "Epoch 24/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7299 - precision: 0.5181 - recall: 0.3122 - val_loss: 0.6957 - val_precision: 0.5681 - val_recall: 0.1711\n",
      "Epoch 25/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7247 - precision: 0.5291 - recall: 0.3207 - val_loss: 0.6901 - val_precision: 0.5991 - val_recall: 0.1768\n",
      "Epoch 26/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7187 - precision: 0.5411 - recall: 0.3303 - val_loss: 0.6846 - val_precision: 0.6346 - val_recall: 0.1849\n",
      "Epoch 27/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7135 - precision: 0.5529 - recall: 0.3398 - val_loss: 0.6791 - val_precision: 0.6717 - val_recall: 0.1951\n",
      "Epoch 28/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7077 - precision: 0.5651 - recall: 0.3506 - val_loss: 0.6737 - val_precision: 0.7107 - val_recall: 0.2080\n",
      "Epoch 29/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.7025 - precision: 0.5774 - recall: 0.3599 - val_loss: 0.6685 - val_precision: 0.7468 - val_recall: 0.2230\n",
      "Epoch 30/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6973 - precision: 0.5896 - recall: 0.3705 - val_loss: 0.6633 - val_precision: 0.7799 - val_recall: 0.2407\n",
      "Epoch 31/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6926 - precision: 0.6018 - recall: 0.3819 - val_loss: 0.6583 - val_precision: 0.8038 - val_recall: 0.2606\n",
      "Epoch 32/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6872 - precision: 0.6146 - recall: 0.3926 - val_loss: 0.6535 - val_precision: 0.8206 - val_recall: 0.2817\n",
      "Epoch 33/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6822 - precision: 0.6268 - recall: 0.4040 - val_loss: 0.6487 - val_precision: 0.8364 - val_recall: 0.3055\n",
      "Epoch 34/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6770 - precision: 0.6392 - recall: 0.4161 - val_loss: 0.6440 - val_precision: 0.8512 - val_recall: 0.3305\n",
      "Epoch 35/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6719 - precision: 0.6528 - recall: 0.4294 - val_loss: 0.6393 - val_precision: 0.8648 - val_recall: 0.3578\n",
      "Epoch 36/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6670 - precision: 0.6644 - recall: 0.4411 - val_loss: 0.6347 - val_precision: 0.8768 - val_recall: 0.3864\n",
      "Epoch 37/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6617 - precision: 0.6771 - recall: 0.4539 - val_loss: 0.6301 - val_precision: 0.8879 - val_recall: 0.4159\n",
      "Epoch 38/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6571 - precision: 0.6884 - recall: 0.4654 - val_loss: 0.6256 - val_precision: 0.8978 - val_recall: 0.4456\n",
      "Epoch 39/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6515 - precision: 0.7017 - recall: 0.4796 - val_loss: 0.6210 - val_precision: 0.9065 - val_recall: 0.4760\n",
      "Epoch 40/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6467 - precision: 0.7119 - recall: 0.4918 - val_loss: 0.6166 - val_precision: 0.9141 - val_recall: 0.5059\n",
      "Epoch 41/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6415 - precision: 0.7237 - recall: 0.5064 - val_loss: 0.6121 - val_precision: 0.9213 - val_recall: 0.5376\n",
      "Epoch 42/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6366 - precision: 0.7349 - recall: 0.5199 - val_loss: 0.6077 - val_precision: 0.9280 - val_recall: 0.5718\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6317 - precision: 0.7453 - recall: 0.5338 - val_loss: 0.6034 - val_precision: 0.9339 - val_recall: 0.6076\n",
      "Epoch 44/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6267 - precision: 0.7553 - recall: 0.5487 - val_loss: 0.5990 - val_precision: 0.9393 - val_recall: 0.6455\n",
      "Epoch 45/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6224 - precision: 0.7637 - recall: 0.5595 - val_loss: 0.5947 - val_precision: 0.9440 - val_recall: 0.6825\n",
      "Epoch 46/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6171 - precision: 0.7750 - recall: 0.5748 - val_loss: 0.5904 - val_precision: 0.9483 - val_recall: 0.7206\n",
      "Epoch 47/50\n",
      "3040026/3040026 [==============================] - 2s 1us/sample - loss: 0.6128 - precision: 0.7838 - recall: 0.5890 - val_loss: 0.5861 - val_precision: 0.9520 - val_recall: 0.7560\n",
      "Epoch 48/50\n",
      "3000000/3040026 [============================>.] - ETA: 0s - loss: 0.6082 - precision: 0.7918 - recall: 0.6004"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "val_data = (X_test,Y_test)\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_precision', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history=model.fit(X_train,\n",
    "                  Y_train,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=val_data,\n",
    "                  batch_size=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the confusion matrix of our predictions\n",
    "#compute predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "y_pred = np.array([np.argmax(probas) for probas in predictions])\n",
    "y_test = np.array([np.argmax(label) for label in Y_test])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()  #Clears the figure\n",
    "prec = history.history['precision']\n",
    "val_prec = history.history['val_precision']\n",
    "plt.plot(epochs, prec, 'bo', label='Training precision')\n",
    "plt.plot(epochs, val_prec, 'r', label='Validation precision')\n",
    "plt.title('Training and validation precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()  #Clears the figure\n",
    "rec = history.history['recall']\n",
    "val_rec = history.history['val_recall']\n",
    "plt.plot(epochs, rec, 'bo', label='Training recall')\n",
    "plt.plot(epochs, val_rec, 'r', label='Validation recall')\n",
    "plt.title('Training and validation recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
