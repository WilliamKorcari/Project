{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "# pandas\n",
    "from pandas import read_csv\n",
    "# matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "#teras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC, Accuracy, Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Which is the name of the dataset? analysis.csv\n",
      "\n",
      "Select first column: \n",
      "2\n",
      "\n",
      "Select last col: \n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = input('\\nWhich is the name of the dataset? ')\n",
    "dataframe = read_csv(dataset, header=0)\n",
    "dataset = dataframe.values\n",
    "#dataset = np.random.shuffle(dataset)\n",
    "first_col = input(\"\\nSelect first column: \\n\") #2\n",
    "last_col = input('\\nSelect last col: \\n')          #15\n",
    "\n",
    "X = dataset[:,int(first_col):int(last_col)].astype(float)   # columns from 3rd to 14th into X\n",
    "Y = dataset[:,int(last_col)] #label column (15th) into Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "#One-hot encoding\n",
    "transformed_Y = to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:\n",
      " Total: 3800033\n",
      " Background: 3713773 \n",
      " Signal: 86260 \n",
      " Signal samples are 2.27% of the total\n"
     ]
    }
   ],
   "source": [
    "bkg, sgn = np.bincount(encoded_Y)\n",
    "\n",
    "total =  bkg + sgn\n",
    "print('Samples:\\n Total: {}\\n Background: {} \\n Signal: {} \\n Signal samples are {:.2f}% of the total'.format(total, bkg, sgn, 100*sgn/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "                                                    transformed_Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=seed,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (2850024, 2)\n",
      "Validation labels shape: (950009, 2)\n",
      "Training features shape: (2850024, 13)\n",
      "Validation features shape: (950009, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Training labels shape:', Y_train.shape)\n",
    "print('Validation labels shape:', Y_test.shape)\n",
    "\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    AUC(name = 'AUC'),\n",
    "    Accuracy(name = 'accuracy'),\n",
    "    Precision(name = 'precision'),\n",
    "    Recall(name = 'recall')    \n",
    "]\n",
    "\n",
    "\n",
    "def make_model(metrics = METRICS, output_bias = None):   \n",
    "    \n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)    \n",
    "    #Initialising NN\n",
    "    model = Sequential()\n",
    "\n",
    "    #First layer\n",
    "    model.add(Dense(8, activation='relu', input_shape=(13,)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Second layer\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "   # model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr= 0.0001),\n",
    "                  metrics=metrics\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 150000\n",
    "val_data = (X_test,Y_test)\n",
    "#checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_precision', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_precision',\n",
    "    verbose = 1,\n",
    "    patience = 70,\n",
    "    mode = 'max',\n",
    "    restore_best_weights = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 246\n",
      "Trainable params: 246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5548207 , 0.5408166 ],\n",
       "       [0.5718665 , 0.51383585],\n",
       "       [0.55785865, 0.47869998],\n",
       "       [0.5706248 , 0.5012827 ],\n",
       "       [0.559022  , 0.48646492],\n",
       "       [0.55066365, 0.5225628 ],\n",
       "       [0.54891723, 0.5088631 ],\n",
       "       [0.5472307 , 0.49558932],\n",
       "       [0.5755338 , 0.52413446],\n",
       "       [0.60277104, 0.516567  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0483\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, Y_test, batch_size = BATCH_SIZE, verbose = 0)\n",
    "print(\"Loss: {:0.4f}\".format(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.76243763])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([sgn/bkg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45471734, 0.78484946],\n",
       "       [0.4675188 , 0.56701595],\n",
       "       [0.5611703 , 0.6682617 ],\n",
       "       [0.48144564, 0.6046998 ],\n",
       "       [0.56791794, 0.6453167 ],\n",
       "       [0.48240045, 0.6196639 ],\n",
       "       [0.3844213 , 0.5881004 ],\n",
       "       [0.4983701 , 0.6339977 ],\n",
       "       [0.42116925, 0.54520005],\n",
       "       [0.45814532, 0.56384915]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(output_bias = initial_bias)\n",
    "model.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7816961fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.51\n",
      "Weight for class 1: 22.03\n"
     ]
    }
   ],
   "source": [
    "weight_for_0 = (1 / bkg)*(total)/2.0\n",
    "weight_for_1 = (1 / sgn)*(total)/2.0\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2850024 samples, validate on 950009 samples\n",
      "Epoch 1/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8306 - AUC: 0.5016 - accuracy: 1.5860e-04 - precision: 0.5132 - recall: 0.6775 - val_loss: 0.7111 - val_AUC: 0.4579 - val_accuracy: 0.0000e+00 - val_precision: 0.5184 - val_recall: 0.9441\n",
      "Epoch 2/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8269 - AUC: 0.5012 - accuracy: 1.5175e-04 - precision: 0.5123 - recall: 0.6721 - val_loss: 0.7103 - val_AUC: 0.4567 - val_accuracy: 0.0000e+00 - val_precision: 0.5177 - val_recall: 0.9400\n",
      "Epoch 3/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8191 - AUC: 0.5013 - accuracy: 1.4526e-04 - precision: 0.5111 - recall: 0.6657 - val_loss: 0.7097 - val_AUC: 0.4551 - val_accuracy: 0.0000e+00 - val_precision: 0.5170 - val_recall: 0.9358\n",
      "Epoch 4/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8194 - AUC: 0.5018 - accuracy: 1.4193e-04 - precision: 0.5100 - recall: 0.6600 - val_loss: 0.7092 - val_AUC: 0.4533 - val_accuracy: 0.0000e+00 - val_precision: 0.5162 - val_recall: 0.9315\n",
      "Epoch 5/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8140 - AUC: 0.5000 - accuracy: 1.3982e-04 - precision: 0.5089 - recall: 0.6536 - val_loss: 0.7092 - val_AUC: 0.4496 - val_accuracy: 0.0000e+00 - val_precision: 0.5152 - val_recall: 0.9267\n",
      "Epoch 6/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8097 - AUC: 0.5032 - accuracy: 1.3474e-04 - precision: 0.5077 - recall: 0.6471 - val_loss: 0.7087 - val_AUC: 0.4482 - val_accuracy: 0.0000e+00 - val_precision: 0.5144 - val_recall: 0.9226\n",
      "Epoch 7/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8056 - AUC: 0.5027 - accuracy: 1.3053e-04 - precision: 0.5073 - recall: 0.6424 - val_loss: 0.7083 - val_AUC: 0.4468 - val_accuracy: 0.0000e+00 - val_precision: 0.5137 - val_recall: 0.9184\n",
      "Epoch 8/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.8030 - AUC: 0.4960 - accuracy: 1.2105e-04 - precision: 0.5056 - recall: 0.6365 - val_loss: 0.7094 - val_AUC: 0.4398 - val_accuracy: 0.0000e+00 - val_precision: 0.5118 - val_recall: 0.9120\n",
      "Epoch 9/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7992 - AUC: 0.4936 - accuracy: 1.1614e-04 - precision: 0.5042 - recall: 0.6305 - val_loss: 0.7091 - val_AUC: 0.4376 - val_accuracy: 0.0000e+00 - val_precision: 0.5109 - val_recall: 0.9068\n",
      "Epoch 10/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7950 - AUC: 0.4930 - accuracy: 1.1210e-04 - precision: 0.5033 - recall: 0.6249 - val_loss: 0.7091 - val_AUC: 0.4347 - val_accuracy: 0.0000e+00 - val_precision: 0.5098 - val_recall: 0.9013\n",
      "Epoch 11/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7942 - AUC: 0.4923 - accuracy: 1.0702e-04 - precision: 0.5026 - recall: 0.6204 - val_loss: 0.7087 - val_AUC: 0.4332 - val_accuracy: 0.0000e+00 - val_precision: 0.5089 - val_recall: 0.8961\n",
      "Epoch 12/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7870 - AUC: 0.4906 - accuracy: 1.0193e-04 - precision: 0.5012 - recall: 0.6145 - val_loss: 0.7092 - val_AUC: 0.4276 - val_accuracy: 0.0000e+00 - val_precision: 0.5072 - val_recall: 0.8889\n",
      "Epoch 13/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7873 - AUC: 0.4900 - accuracy: 1.0737e-04 - precision: 0.5004 - recall: 0.6093 - val_loss: 0.7089 - val_AUC: 0.4261 - val_accuracy: 0.0000e+00 - val_precision: 0.5062 - val_recall: 0.8833\n",
      "Epoch 14/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7839 - AUC: 0.4920 - accuracy: 1.0053e-04 - precision: 0.4999 - recall: 0.6053 - val_loss: 0.7087 - val_AUC: 0.4241 - val_accuracy: 0.0000e+00 - val_precision: 0.5049 - val_recall: 0.8770\n",
      "Epoch 15/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7818 - AUC: 0.4921 - accuracy: 9.7192e-05 - precision: 0.4995 - recall: 0.6007 - val_loss: 0.7084 - val_AUC: 0.4226 - val_accuracy: 0.0000e+00 - val_precision: 0.5037 - val_recall: 0.8713\n",
      "Epoch 16/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7797 - AUC: 0.4905 - accuracy: 9.6841e-05 - precision: 0.4982 - recall: 0.5952 - val_loss: 0.7089 - val_AUC: 0.4181 - val_accuracy: 0.0000e+00 - val_precision: 0.5017 - val_recall: 0.8630\n",
      "Epoch 17/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7764 - AUC: 0.4884 - accuracy: 9.7543e-05 - precision: 0.4964 - recall: 0.5886 - val_loss: 0.7097 - val_AUC: 0.4120 - val_accuracy: 0.0000e+00 - val_precision: 0.4990 - val_recall: 0.8530\n",
      "Epoch 18/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7739 - AUC: 0.4863 - accuracy: 9.1754e-05 - precision: 0.4956 - recall: 0.5842 - val_loss: 0.7093 - val_AUC: 0.4114 - val_accuracy: 0.0000e+00 - val_precision: 0.4977 - val_recall: 0.8467\n",
      "Epoch 19/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7732 - AUC: 0.4854 - accuracy: 9.0175e-05 - precision: 0.4950 - recall: 0.5799 - val_loss: 0.7091 - val_AUC: 0.4098 - val_accuracy: 0.0000e+00 - val_precision: 0.4961 - val_recall: 0.8394\n",
      "Epoch 20/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7707 - AUC: 0.4848 - accuracy: 8.6666e-05 - precision: 0.4953 - recall: 0.5767 - val_loss: 0.7085 - val_AUC: 0.4103 - val_accuracy: 0.0000e+00 - val_precision: 0.4950 - val_recall: 0.8335\n",
      "Epoch 21/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7689 - AUC: 0.4851 - accuracy: 8.3333e-05 - precision: 0.4953 - recall: 0.5735 - val_loss: 0.7079 - val_AUC: 0.4105 - val_accuracy: 0.0000e+00 - val_precision: 0.4940 - val_recall: 0.8274\n",
      "Epoch 22/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7671 - AUC: 0.4925 - accuracy: 7.3333e-05 - precision: 0.4953 - recall: 0.5701 - val_loss: 0.7075 - val_AUC: 0.4104 - val_accuracy: 0.0000e+00 - val_precision: 0.4928 - val_recall: 0.8210\n",
      "Epoch 23/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7678 - AUC: 0.4937 - accuracy: 7.7719e-05 - precision: 0.4948 - recall: 0.5654 - val_loss: 0.7076 - val_AUC: 0.4073 - val_accuracy: 0.0000e+00 - val_precision: 0.4905 - val_recall: 0.8110\n",
      "Epoch 24/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7655 - AUC: 0.4937 - accuracy: 7.5613e-05 - precision: 0.4944 - recall: 0.5617 - val_loss: 0.7072 - val_AUC: 0.4072 - val_accuracy: 0.0000e+00 - val_precision: 0.4891 - val_recall: 0.8038\n",
      "Epoch 25/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7638 - AUC: 0.4931 - accuracy: 7.1403e-05 - precision: 0.4940 - recall: 0.5580 - val_loss: 0.7069 - val_AUC: 0.4063 - val_accuracy: 0.0000e+00 - val_precision: 0.4873 - val_recall: 0.7958\n",
      "Epoch 26/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7610 - AUC: 0.4931 - accuracy: 6.6842e-05 - precision: 0.4939 - recall: 0.5549 - val_loss: 0.7063 - val_AUC: 0.4070 - val_accuracy: 0.0000e+00 - val_precision: 0.4862 - val_recall: 0.7889\n",
      "Epoch 27/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7587 - AUC: 0.4951 - accuracy: 6.6842e-05 - precision: 0.4942 - recall: 0.5516 - val_loss: 0.7059 - val_AUC: 0.4073 - val_accuracy: 0.0000e+00 - val_precision: 0.4848 - val_recall: 0.7815\n",
      "Epoch 28/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7587 - AUC: 0.4950 - accuracy: 6.1754e-05 - precision: 0.4933 - recall: 0.5477 - val_loss: 0.7065 - val_AUC: 0.4020 - val_accuracy: 0.0000e+00 - val_precision: 0.4812 - val_recall: 0.7689\n",
      "Epoch 29/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7554 - AUC: 0.4911 - accuracy: 5.9298e-05 - precision: 0.4924 - recall: 0.5436 - val_loss: 0.7064 - val_AUC: 0.4004 - val_accuracy: 0.0000e+00 - val_precision: 0.4789 - val_recall: 0.7594\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7565 - AUC: 0.4883 - accuracy: 6.4210e-05 - precision: 0.4923 - recall: 0.5398 - val_loss: 0.7061 - val_AUC: 0.4002 - val_accuracy: 0.0000e+00 - val_precision: 0.4773 - val_recall: 0.7514\n",
      "Epoch 31/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7539 - AUC: 0.4882 - accuracy: 5.8070e-05 - precision: 0.4925 - recall: 0.5380 - val_loss: 0.7063 - val_AUC: 0.3975 - val_accuracy: 0.0000e+00 - val_precision: 0.4746 - val_recall: 0.7413\n",
      "Epoch 32/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7510 - AUC: 0.4857 - accuracy: 5.6491e-05 - precision: 0.4910 - recall: 0.5341 - val_loss: 0.7075 - val_AUC: 0.3897 - val_accuracy: 0.0000e+00 - val_precision: 0.4693 - val_recall: 0.7251\n",
      "Epoch 33/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7502 - AUC: 0.4844 - accuracy: 5.2456e-05 - precision: 0.4901 - recall: 0.5305 - val_loss: 0.7073 - val_AUC: 0.3885 - val_accuracy: 0.0000e+00 - val_precision: 0.4666 - val_recall: 0.7151\n",
      "Epoch 34/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7498 - AUC: 0.4831 - accuracy: 5.0701e-05 - precision: 0.4890 - recall: 0.5265 - val_loss: 0.7072 - val_AUC: 0.3872 - val_accuracy: 0.0000e+00 - val_precision: 0.4637 - val_recall: 0.7050\n",
      "Epoch 35/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7491 - AUC: 0.4822 - accuracy: 5.0526e-05 - precision: 0.4894 - recall: 0.5246 - val_loss: 0.7068 - val_AUC: 0.3875 - val_accuracy: 0.0000e+00 - val_precision: 0.4616 - val_recall: 0.6960\n",
      "Epoch 36/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7471 - AUC: 0.4821 - accuracy: 4.4386e-05 - precision: 0.4889 - recall: 0.5210 - val_loss: 0.7061 - val_AUC: 0.3891 - val_accuracy: 0.0000e+00 - val_precision: 0.4602 - val_recall: 0.6882\n",
      "Epoch 37/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7465 - AUC: 0.4834 - accuracy: 4.5438e-05 - precision: 0.4899 - recall: 0.5196 - val_loss: 0.7055 - val_AUC: 0.3907 - val_accuracy: 0.0000e+00 - val_precision: 0.4590 - val_recall: 0.6806\n",
      "Epoch 38/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7448 - AUC: 0.4843 - accuracy: 4.5965e-05 - precision: 0.4904 - recall: 0.5172 - val_loss: 0.7050 - val_AUC: 0.3919 - val_accuracy: 0.0000e+00 - val_precision: 0.4575 - val_recall: 0.6726\n",
      "Epoch 39/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7455 - AUC: 0.4832 - accuracy: 4.5438e-05 - precision: 0.4906 - recall: 0.5148 - val_loss: 0.7047 - val_AUC: 0.3919 - val_accuracy: 0.0000e+00 - val_precision: 0.4555 - val_recall: 0.6637\n",
      "Epoch 40/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7432 - AUC: 0.4836 - accuracy: 4.1052e-05 - precision: 0.4910 - recall: 0.5124 - val_loss: 0.7042 - val_AUC: 0.3930 - val_accuracy: 0.0000e+00 - val_precision: 0.4541 - val_recall: 0.6557\n",
      "Epoch 41/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7434 - AUC: 0.4831 - accuracy: 5.0000e-05 - precision: 0.4904 - recall: 0.5085 - val_loss: 0.7043 - val_AUC: 0.3901 - val_accuracy: 0.0000e+00 - val_precision: 0.4505 - val_recall: 0.6425\n",
      "Epoch 42/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7419 - AUC: 0.4834 - accuracy: 3.9298e-05 - precision: 0.4906 - recall: 0.5057 - val_loss: 0.7039 - val_AUC: 0.3908 - val_accuracy: 0.0000e+00 - val_precision: 0.4492 - val_recall: 0.6348\n",
      "Epoch 43/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7401 - AUC: 0.4824 - accuracy: 3.9473e-05 - precision: 0.4897 - recall: 0.5023 - val_loss: 0.7044 - val_AUC: 0.3858 - val_accuracy: 0.0000e+00 - val_precision: 0.4440 - val_recall: 0.6195\n",
      "Epoch 44/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7387 - AUC: 0.4872 - accuracy: 3.8947e-05 - precision: 0.4885 - recall: 0.4990 - val_loss: 0.7043 - val_AUC: 0.3845 - val_accuracy: 0.0000e+00 - val_precision: 0.4411 - val_recall: 0.6090\n",
      "Epoch 45/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7375 - AUC: 0.4948 - accuracy: 4.3158e-05 - precision: 0.4889 - recall: 0.4963 - val_loss: 0.7037 - val_AUC: 0.3860 - val_accuracy: 0.0000e+00 - val_precision: 0.4403 - val_recall: 0.6026\n",
      "Epoch 46/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7376 - AUC: 0.4961 - accuracy: 3.7719e-05 - precision: 0.4890 - recall: 0.4936 - val_loss: 0.7035 - val_AUC: 0.3860 - val_accuracy: 0.0000e+00 - val_precision: 0.4385 - val_recall: 0.5946\n",
      "Epoch 47/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7373 - AUC: 0.4966 - accuracy: 3.5263e-05 - precision: 0.4890 - recall: 0.4916 - val_loss: 0.7031 - val_AUC: 0.3872 - val_accuracy: 0.0000e+00 - val_precision: 0.4377 - val_recall: 0.5881\n",
      "Epoch 48/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7359 - AUC: 0.4975 - accuracy: 3.4737e-05 - precision: 0.4893 - recall: 0.4894 - val_loss: 0.7026 - val_AUC: 0.3887 - val_accuracy: 0.0000e+00 - val_precision: 0.4369 - val_recall: 0.5817\n",
      "Epoch 49/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7374 - AUC: 0.4989 - accuracy: 3.3158e-05 - precision: 0.4901 - recall: 0.4875 - val_loss: 0.7021 - val_AUC: 0.3903 - val_accuracy: 0.0000e+00 - val_precision: 0.4363 - val_recall: 0.5755\n",
      "Epoch 50/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7343 - AUC: 0.5004 - accuracy: 3.3508e-05 - precision: 0.4910 - recall: 0.4858 - val_loss: 0.7016 - val_AUC: 0.3921 - val_accuracy: 0.0000e+00 - val_precision: 0.4358 - val_recall: 0.5694\n",
      "Epoch 51/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7345 - AUC: 0.5015 - accuracy: 3.3333e-05 - precision: 0.4917 - recall: 0.4836 - val_loss: 0.7011 - val_AUC: 0.3940 - val_accuracy: 0.0000e+00 - val_precision: 0.4355 - val_recall: 0.5636\n",
      "Epoch 52/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7335 - AUC: 0.5030 - accuracy: 3.0175e-05 - precision: 0.4923 - recall: 0.4820 - val_loss: 0.7007 - val_AUC: 0.3955 - val_accuracy: 0.0000e+00 - val_precision: 0.4348 - val_recall: 0.5572\n",
      "Epoch 53/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7318 - AUC: 0.5034 - accuracy: 2.9298e-05 - precision: 0.4925 - recall: 0.4795 - val_loss: 0.7003 - val_AUC: 0.3971 - val_accuracy: 0.0000e+00 - val_precision: 0.4341 - val_recall: 0.5508\n",
      "Epoch 54/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7324 - AUC: 0.5046 - accuracy: 2.8947e-05 - precision: 0.4933 - recall: 0.4776 - val_loss: 0.6999 - val_AUC: 0.3986 - val_accuracy: 0.0000e+00 - val_precision: 0.4334 - val_recall: 0.5445\n",
      "Epoch 55/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7306 - AUC: 0.5052 - accuracy: 2.8421e-05 - precision: 0.4933 - recall: 0.4752 - val_loss: 0.6998 - val_AUC: 0.3977 - val_accuracy: 0.0000e+00 - val_precision: 0.4310 - val_recall: 0.5355\n",
      "Epoch 56/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7297 - AUC: 0.5042 - accuracy: 3.0351e-05 - precision: 0.4924 - recall: 0.4723 - val_loss: 0.7003 - val_AUC: 0.3926 - val_accuracy: 0.0000e+00 - val_precision: 0.4255 - val_recall: 0.5216\n",
      "Epoch 57/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7287 - AUC: 0.5030 - accuracy: 2.6491e-05 - precision: 0.4911 - recall: 0.4685 - val_loss: 0.7007 - val_AUC: 0.3880 - val_accuracy: 0.0000e+00 - val_precision: 0.4208 - val_recall: 0.5108\n",
      "Epoch 58/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7287 - AUC: 0.5028 - accuracy: 2.3684e-05 - precision: 0.4909 - recall: 0.4666 - val_loss: 0.7006 - val_AUC: 0.3875 - val_accuracy: 0.0000e+00 - val_precision: 0.4189 - val_recall: 0.5038\n",
      "Epoch 59/1000\n",
      "2850024/2850024 [==============================] - 10s 3us/sample - loss: 0.7270 - AUC: 0.5026 - accuracy: 2.9123e-05 - precision: 0.4904 - recall: 0.4639 - val_loss: 0.7004 - val_AUC: 0.3877 - val_accuracy: 0.0000e+00 - val_precision: 0.4173 - val_recall: 0.4971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7281 - AUC: 0.5038 - accuracy: 2.3859e-05 - precision: 0.4908 - recall: 0.4621 - val_loss: 0.7000 - val_AUC: 0.3889 - val_accuracy: 0.0000e+00 - val_precision: 0.4164 - val_recall: 0.4910\n",
      "Epoch 61/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7274 - AUC: 0.5031 - accuracy: 2.4561e-05 - precision: 0.4901 - recall: 0.4587 - val_loss: 0.7002 - val_AUC: 0.3863 - val_accuracy: 0.0000e+00 - val_precision: 0.4127 - val_recall: 0.4805\n",
      "Epoch 62/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7256 - AUC: 0.5044 - accuracy: 2.7544e-05 - precision: 0.4907 - recall: 0.4569 - val_loss: 0.6998 - val_AUC: 0.3874 - val_accuracy: 0.0000e+00 - val_precision: 0.4118 - val_recall: 0.4747\n",
      "Epoch 63/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7249 - AUC: 0.5029 - accuracy: 2.2456e-05 - precision: 0.4893 - recall: 0.4535 - val_loss: 0.7003 - val_AUC: 0.3825 - val_accuracy: 0.0000e+00 - val_precision: 0.4068 - val_recall: 0.4630\n",
      "Epoch 64/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7238 - AUC: 0.5028 - accuracy: 2.1228e-05 - precision: 0.4887 - recall: 0.4505 - val_loss: 0.7000 - val_AUC: 0.3834 - val_accuracy: 0.0000e+00 - val_precision: 0.4058 - val_recall: 0.4573\n",
      "Epoch 65/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7230 - AUC: 0.5021 - accuracy: 2.1052e-05 - precision: 0.4889 - recall: 0.4485 - val_loss: 0.7001 - val_AUC: 0.3820 - val_accuracy: 0.0000e+00 - val_precision: 0.4033 - val_recall: 0.4503\n",
      "Epoch 66/1000\n",
      "2850024/2850024 [==============================] - 9s 3us/sample - loss: 0.7223 - AUC: 0.5010 - accuracy: 2.1579e-05 - precision: 0.4884 - recall: 0.4457 - val_loss: 0.6999 - val_AUC: 0.3819 - val_accuracy: 0.0000e+00 - val_precision: 0.4015 - val_recall: 0.4438\n",
      "Epoch 67/1000\n",
      "2250000/2850024 [======================>.......] - ETA: 1s - loss: 0.7219 - AUC: 0.5022 - accuracy: 2.2889e-05 - precision: 0.4890 - recall: 0.4442"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history=model.fit(X_train,\n",
    "                  Y_train,\n",
    "                  epochs = EPOCHS,\n",
    "                  shuffle = True,\n",
    "                  validation_data=val_data,\n",
    "                  callbacks = [early_stopping],\n",
    "                  batch_size = BATCH_SIZE,\n",
    "                  class_weight=class_weight\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_json = model.to_json()\n",
    "#with open(\"model.json\", \"w\") as json_file:\n",
    "    #json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics =  ['loss', 'AUC', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#compute predictions\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "y_pred = np.array([np.argmax(probas) for probas in predictions])\n",
    "y_test = np.array([np.argmax(label) for label in Y_test])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels = [1, 0])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = unique_labels(y_test, y_pred)\n",
    "class_names = unique_labels(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          class_names = None,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    if class_names is None:\n",
    "        x_labels = y_labels = classes\n",
    "    else:\n",
    "        x_labels = y_labels = class_names\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=x_labels, yticklabels=y_labels,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, classes, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()  #Clears the figure\n",
    "prec = history.history['precision']\n",
    "val_prec = history.history['val_precision']\n",
    "plt.plot(epochs, prec, 'bo', label='Training precision')\n",
    "plt.plot(epochs, val_prec, 'r', label='Validation precision')\n",
    "plt.title('Training and validation precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()  #Clears the figure\n",
    "rec = history.history['recall']\n",
    "val_rec = history.history['val_recall']\n",
    "plt.plot(epochs, rec, 'bo', label='Training recall')\n",
    "plt.plot(epochs, val_rec, 'r', label='Validation recall')\n",
    "plt.title('Training and validation recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
